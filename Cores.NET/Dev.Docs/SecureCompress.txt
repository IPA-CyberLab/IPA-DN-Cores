SecureCompress とは、本ライブラリでサポートする、安全なストリーム型圧縮・暗号化フィルタである。
内部的には、gzip 圧縮と、XTS-AES 256bit 暗号を使用している。

任意のストリームを圧縮・解凍できる。圧縮・解凍においては、シークを一切使用しない。これにより、HTTP 経由でのバイナリオブジェクトの読み書きで利用可能である。

「安全な」の意味:
(1) ブロック分割されており、HDD の故障等でビット反転によるデータ損失が生じても、その反転が生じたブロックのみが復元不能となり、それ以外のブロックは復元可能であることを意味する。
(2) XTS-AES 256bit により暗号化が可能であり、パスフレーズを知らなければ、解読はほぼ不可能である。


■ ファイルヘッダ部
ファイルの先頭に存在する。
ヘッダは、

\r\n\r\n!!__[MetaData:SecureCompressFirstHeader]__!!\r\n

という文字列に続き、JSON 文字列で構成される。
余った部分は、NULL 文字で埋められる。

JSON 文字列は、4000 bytes を超えてはならない。
ファイルヘッダ領域は、固定長の 4096 bytes とし、NULL 文字でパディングする。

JSON には、以下の情報が記載されている。

・ ファイルフォーマット
・ バージョン番号
・ フラグ (暗号化の有無)
・ その他必要なメタデータ
・ 暗号化機能を使用する場合の SaltedPassword、MasterKeyEncryptedByPassword の値
・ 元データのサイズ (ヒント)

ヘッダ部は 2 個書かれる。1 個目が通常読み取りに利用される。2 個目は、1 個目のヘッダ部が何らかの理由で破損した場合のバックアップである。


■ ブロックの概念
ブロックとは、ある程度のデータの固まりである。これは、HDD の故障等でビット反転が生じたときにそのビット反転で影響を受ける範囲である。

1 つのブロックは、「ブロックヘッダ＋圧縮済みデータ」で構成される。


■ ブロックヘッダ
1 つのブロックは、

\r\n\r\n!!__[MetaData:SecureCompressBlockHeader]__!!\r\n

という文字列に続き、JSON 文字列で構成される。
JSON 文字列は、4000 bytes を超えてはならない。
ブロックヘッダ領域は、固定長の 4096 bytes とし、NULL 文字でパディングする。

JSON には、以下の情報が記載されている。

・ チャンク番号
・ ヘッダに続く圧縮済みのデータのサイズ (int)
・ このデータの元データ中における開始位置 (long)
・ このデータの元データのサイズ (int)
・ 圧縮済みデータのパディング前 (暗号化前) のサイズ
・ 元データの SHA1, MD5
・ 圧縮・暗号化後の SHA1, MD5

ブロックヘッダに続き、そのブロックヘッダが受け持つ圧縮済み (暗号化機能を用いている場合は、圧縮の後暗号化済み) データ本体が連続する。

圧縮済み (圧縮＋暗号化済み) データについて

  1. 元データ (1 バイト単位のストリーム)
     ↓ ここで gzip 圧縮をする。gzip 圧縮は、このブロックのみを対象
     ↓ としたコンテキストで圧縮するものである。先立つブロックとは無関係。
  2. 圧縮結果データ (1 バイト単位のストリーム)
     ↓
  3. 2 の圧縮結果データの末尾にパディングを施し、
     4096 bytes の倍数のサイズとする。
     パディングは、暗号化もする場合は乱数とし、
     暗号化しない場合は NULL 文字とする。
     ↓
  4. XTS-AES256 により暗号化する。3 と比較して、サイズは変わらない。
     暗号化済み済データは、4096 bytes 単位となる。
     XTS-AES アルゴリズムにおけるセクタ番号は、
     このデータの元データ中における開始位置 (long) とする。

したがって、圧縮済み (圧縮＋暗号化済み) データは、必ず 4096 bytes の倍数サイズとなる。

上述したとおり、ブロックヘッダも 4096 bytes 固定なので、ブロックヘッダは必ず 4096 bytes の整数倍のオフセットでのみ出現することになる。


■ ブロックデータのサイズ制限
ブロックデータの元データのサイズは、1MB (1024 * 1024) とする。

これを圧縮するので、圧縮先サイズは、どれだけひどくても 1MB 程度であるが、ひどい圧縮アルゴリズムによっては 2 倍くらいに増える可能性もあるので (ないと思われるが)、念のため、圧縮先サイズは 2MB (2 * 1024 * 1024) をエラー境界値とする。それ以上になることは、まず、ないはずである。


■ 複数 CPU における複数ブロックの並行処理
マルチコアホストにおいて圧縮や暗号化の速度を劇的に高速化するため、複数 CPU を同時に利用することができる。

複数 CPU を利用する場合の処理は、以下のようになる。

[圧縮・暗号化]

  1. 処理対象データストリームを複数 CPU 分読み込む。
     これは、1 つのスレッドで行なう。
     つまり、結構メモリを消費する。
     仮に 8 CPU とすると、原則 8MB くらいメモリを消費し、GC もあるので、
     結構なメモリ量となる。GC の調子にもよるが、おそらく数十 MB くらい消費
     するであろう。
     ↓
  2. 読み込んだブロックを複数 CPU で並列処理する。
     ↓
  3. 並列処理が完了し、書き込むべきデータが生成されたら、順番 (必ずオフセット
     の順番であること) に書き込みデータに整列し、書き込みを実施する。
     書き込みは、1 つのスレッドで行なう。

[復号・展開]

  1. 1 スレッドを用いて、処理対象データストリームを読み込む。
     まず、ヘッダ部を探す。ヘッダ部の探索は、現在位置 + (N * 4096) bytes 目
     (N は 0 以上の整数でインクリメントしていく) を読み込み、
     そこに !!__[MetaData:SecureCompressBlockHeader]__!!\r\n という文字列
     が存在するかどうかで判別する。
     ↓
  2. ヘッダをパースし、JSON 形式で解釈する。
     ↓
  3. ヘッダに続く圧縮済みのデータのサイズ分、データを読み込む。
     ↓
  4. 複数 CPU を活用して以下を並列実施する。
     (1) XTS-AES256 により復号化する。(必要な場合)
         ↓
     (2) 復号化されたデータ (圧縮済み) はパディングされている可能性がある。
         パディングを除去する。
         ↓
     (3) 圧縮を展開する。
         展開されたデータサイズが、JSON ヘッダに書いてあるとおりで一致する
         ことを確認する。
     ↓
  5. 結果を並べて、出力先ファイルストリームに書き込む。


■ ビット破損の場合の救済
上記の仕組みにより、仮にデータにビット破損 (データ化け) が発生したとしても、通常、途中でビットが挿入される (サイズが変わる) 可能性はないので、そのデータ破損が存在するブロックのデータのみが失われるのみであり、それ以外のブロックには影響が生じない。

そして、あるブロックの復元エラーになったとしても、そのエラーは警告として画面表示した上で、4096 bytes 単位でシークした次のブロックを復元処理すればよいのである。


■ 末尾ヘッダ
末尾には以下のヘッダを付ける。

\r\n\r\n!!__[MetaData:SecureCompressFinalHeader]__!!\r\n

という文字列に続き、JSON 文字列で構成される。
JSON 文字列は、4000 bytes を超えてはならない。
ブロックヘッダ領域は、固定長の 4096 bytes とし、NULL 文字でパディングする。

JSON には、以下の情報が記載されている。

・ 合計チャンクサイズ
・ 合計チャンク数

・ 元データの合計サイズ (long)
・ 圧縮後データの合計サイズ (参考) (long)

・ 元データのサイズ
・ 元データの SHA1, MD5
・ この末尾ヘッダの直前までの SHA1, MD5
・ ヘッダ部の JSON のコピー (ヘッダが破損してしまった場合用)

この情報は参考値であり、利用しなくてもよい。


■ オーバーヘッド
仮に圧縮不能な乱数データを本フォーマットを用いて圧縮した場合のオーバーヘッドは、無駄なヘッダ領域 4096 bytes なので、 4096 / (1024 * 1024) = 0.4% である。

そして、実際には圧縮が効率よく成されるので、オーバーヘッドはほとんど問題にならないのである。



